{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:05.130696Z",
     "iopub.status.busy": "2025-11-26T03:16:05.130696Z",
     "iopub.status.idle": "2025-11-26T03:16:11.205867Z",
     "shell.execute_reply": "2025-11-26T03:16:11.205867Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from models.mlp import BlackBoxModel\n",
    "\n",
    "from models.rbf import RBFNet\n",
    "from models.svm import LinearSVM\n",
    "from explainers.model import Model\n",
    "from utils.datasets import dataset_loader\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:11.208875Z",
     "iopub.status.busy": "2025-11-26T03:16:11.208875Z",
     "iopub.status.idle": "2025-11-26T03:16:12.068061Z",
     "shell.execute_reply": "2025-11-26T03:16:12.068061Z"
    }
   },
   "outputs": [],
   "source": [
    "def bold(string):\n",
    "    return \"\\033[1m\" + string + \"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:12.071066Z",
     "iopub.status.busy": "2025-11-26T03:16:12.071066Z",
     "iopub.status.idle": "2025-11-26T03:16:13.163788Z",
     "shell.execute_reply": "2025-11-26T03:16:13.163788Z"
    }
   },
   "outputs": [],
   "source": [
    "name = 'compas'\n",
    "dropped_features = []#UCIDatasets().continuous_features[dataset]\n",
    "dataset = dataset_loader(name, dropped_features=dropped_features, n_bins=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:13.166794Z",
     "iopub.status.busy": "2025-11-26T03:16:13.166794Z",
     "iopub.status.idle": "2025-11-26T03:16:13.969727Z",
     "shell.execute_reply": "2025-11-26T03:16:13.969727Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:14.005731Z",
     "iopub.status.busy": "2025-11-26T03:16:14.005731Z",
     "iopub.status.idle": "2025-11-26T03:16:14.830677Z",
     "shell.execute_reply": "2025-11-26T03:16:14.830677Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, mean, std = dataset.get_split(normalise=False, shuffle=False,\n",
    "                                                                     return_mean_std=True)\n",
    "prop1s = round(np.average(y_train)*100, 2)\n",
    "print(bold(\"Proportion of 1s in Training Data:\") + \" {}%\".format(prop1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:14.833682Z",
     "iopub.status.busy": "2025-11-26T03:16:14.833682Z",
     "iopub.status.idle": "2025-11-26T03:16:15.654234Z",
     "shell.execute_reply": "2025-11-26T03:16:15.653730Z"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X_train)\n",
    "X.columns = dataset.features[:-1]\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_train.columns = dataset.features[:-1]\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_test.columns = dataset.features[:-1]\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "print(bold(\"Dataset:\") + \" {}\\n\".format(name.replace('_', ' ').title()))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:18.243868Z",
     "iopub.status.busy": "2025-11-26T03:16:18.243868Z",
     "iopub.status.idle": "2025-11-26T03:16:19.100541Z",
     "shell.execute_reply": "2025-11-26T03:16:19.100541Z"
    }
   },
   "outputs": [],
   "source": [
    "target_name = 'Status'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "seed = 43\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "std = X_train.std()\n",
    "mean = X_train.mean()\n",
    "\n",
    "for col in ['Priors_Count', 'Time_Served']:\n",
    "    X_train[col] = (X_train[col] - X_train[col].mean()) / X_train[col].std()\n",
    "    X_test[col] = (X_test[col] - X_test[col].mean()) / X_test[col].std()\n",
    "\n",
    "X_train, X_test, y_train, y_test = X_train.values, X_test.values, y_train.values, y_test.values\n",
    "\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train).view(-1, 1)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.FloatTensor(y_test).view(-1, 1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "X_train_tensor = X_train_tensor.to(device)\n",
    "y_train_tensor = y_train_tensor.to(device)\n",
    "X_test_tensor = X_test_tensor.to(device)\n",
    "y_test_tensor = y_test_tensor.to(device)\n",
    "\n",
    "model_raw = BlackBoxModel(input_dim=X_train.shape[1], hidden_dim=10).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model_raw.parameters(), lr=0.01)\n",
    "\n",
    "model_raw.train()\n",
    "for epoch in range(300):\n",
    "    outputs = model_raw(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "model_raw.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model_raw(X_test_tensor)\n",
    "    preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "    accuracy = (preds == y_test_tensor).float().mean().item()\n",
    "accuracy\n",
    "\n",
    "model = Model(model=model_raw, backend=\"pytorch\", data=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:21.191277Z",
     "iopub.status.busy": "2025-11-26T03:16:21.191277Z",
     "iopub.status.idle": "2025-11-26T03:16:22.116890Z",
     "shell.execute_reply": "2025-11-26T03:16:22.113891Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_num = 50\n",
    "X_test = pd.DataFrame(X_test, columns=X.columns)\n",
    "\n",
    "\n",
    "# indice = pd.Index(np.random.choice(len(X_test), size=sample_num, replace=False))\n",
    "indice = pd.Index([ 753,  582,  548,  113,  174,  420,  309,  998,  413, 1054, 1171,\n",
    "             275,  771, 1135,  415,  478,  609,  168,  332,  933,  490,  906,\n",
    "            1073,  128,  107, 1136,   43, 1168,  327,  610,  596,  631, 1205,\n",
    "             534,  597,  220,  911,  198,  743,  985,  231,  865, 1088,  715,\n",
    "             306,  101,  438,   78, 1223,   49,  936,  736,  243,  868, 1096,\n",
    "             937,  381,  767,   63,  323,   44,  943, 1098,  482,  575,  254,\n",
    "             529,  286,  992,  123,   76,  218, 1110,  545,  292,  701, 1226,\n",
    "             844,  363,  811,  754,  266,  904,  958,  590, 1222,  233,   70,\n",
    "             566,   23,  155,  707,   58,  428, 1008, 1057,  342,  629,   81,\n",
    "            1127],\n",
    "           dtype='int64')\n",
    "\n",
    "df_explain = X_test.loc[indice]\n",
    "\n",
    "# y_target = torch.distributions.beta.Beta(0.1, 0.9).sample((sample_num,))\n",
    "y_test = pd.Series(y_test.reshape(-1))\n",
    "y_true = y_test.loc[indice]\n",
    "\n",
    "y = model(torch.FloatTensor(df_explain.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:22.119399Z",
     "iopub.status.busy": "2025-11-26T03:16:22.119399Z",
     "iopub.status.idle": "2025-11-26T03:16:22.976236Z",
     "shell.execute_reply": "2025-11-26T03:16:22.976236Z"
    }
   },
   "outputs": [],
   "source": [
    "def postprocessing(counterfactual_X):\n",
    "\n",
    "    prior_count_col = counterfactual_X['Priors_Count']\n",
    "    time_served_col = counterfactual_X['Time_Served']\n",
    "    counterfactual_X = (counterfactual_X>0.5).replace({False:0 ,True:1})\n",
    "    counterfactual_X['Priors_Count'] = prior_count_col\n",
    "    counterfactual_X['Time_Served'] = time_served_col\n",
    "    \n",
    "    return counterfactual_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLOBE_CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:22.980597Z",
     "iopub.status.busy": "2025-11-26T03:16:22.979600Z",
     "iopub.status.idle": "2025-11-26T03:16:23.797356Z",
     "shell.execute_reply": "2025-11-26T03:16:23.797356Z"
    }
   },
   "outputs": [],
   "source": [
    "from explainers.globe_ce import GLOBE_CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:23.800527Z",
     "iopub.status.busy": "2025-11-26T03:16:23.799407Z",
     "iopub.status.idle": "2025-11-26T03:16:24.632533Z",
     "shell.execute_reply": "2025-11-26T03:16:24.631530Z"
    }
   },
   "outputs": [],
   "source": [
    "normalise = None\n",
    "\n",
    "# AReS initiated to determine bin widths for costs\n",
    "from explainers.ares import AReS\n",
    "\n",
    "X_for_ares = (\n",
    "    dataset.data.drop(columns=[target_name])\n",
    "    .apply(pd.to_numeric, errors=\"coerce\")\n",
    "    .fillna(0)\n",
    "    .astype(np.float32)\n",
    ")\n",
    "\n",
    "ares = AReS(model=model_raw, dataset=dataset, X=X_for_ares, n_bins=10, normalise=normalise)  # Use raw model for AReS\n",
    "bin_widths = ares.bin_widths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:24.635533Z",
     "iopub.status.busy": "2025-11-26T03:16:24.634533Z",
     "iopub.status.idle": "2025-11-26T03:16:25.456316Z",
     "shell.execute_reply": "2025-11-26T03:16:25.455312Z"
    }
   },
   "outputs": [],
   "source": [
    "# example of ordinal features usage\n",
    "ordinal_features = ['Present-Employment'] if name == 'german_credit' else []\n",
    "# initialise GLOBE_CE\n",
    "globe_ce = GLOBE_CE(model=model_raw, dataset=dataset, X=df_explain, affected_subgroup=None,\n",
    "                    dropped_features=dropped_features, ordinal_features=ordinal_features, delta_init='zeros',\n",
    "                    normalise=normalise, bin_widths=bin_widths, monotonicity=None, p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:25.459316Z",
     "iopub.status.busy": "2025-11-26T03:16:25.458316Z",
     "iopub.status.idle": "2025-11-26T03:16:26.841652Z",
     "shell.execute_reply": "2025-11-26T03:16:26.841652Z"
    }
   },
   "outputs": [],
   "source": [
    "globe_ce.sample(n_sample=sample_num, magnitude=2, sparsity_power=1,  \n",
    "                idxs=None, n_features=5, disable_tqdm=False,  \n",
    "                plot=True, seed=0, scheme='random', dropped_features=dropped_features)\n",
    "delta = globe_ce.best_delta  # pick best delta\n",
    "globe_ce.select_n_deltas(n_div=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:26.844071Z",
     "iopub.status.busy": "2025-11-26T03:16:26.844071Z",
     "iopub.status.idle": "2025-11-26T03:16:27.839331Z",
     "shell.execute_reply": "2025-11-26T03:16:27.839331Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=globe_ce.deltas_div.shape[0], dpi=150)\n",
    "fig.set_figwidth(12)\n",
    "fig.set_figheight(3)\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "for i in range(globe_ce.deltas_div.shape[0]):\n",
    "    delta_cost = globe_ce.deltas_div[i] * globe_ce.feature_costs_vector\n",
    "    cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    j, k = 0, 0\n",
    "    for feature in globe_ce.features_tree:\n",
    "        if not globe_ce.features_tree[feature]:\n",
    "            ax[i].bar(range(j, j+1), delta_cost[j], hatch='/',\n",
    "                        linewidth=1, edgecolor='black', color=cycle[k%len(cycle)])\n",
    "            j += 1\n",
    "            k += 1\n",
    "        else:\n",
    "            feature_values = globe_ce.features_tree[feature]\n",
    "            n_f = len(feature_values)\n",
    "            ax[2].bar(range(j, j+n_f), delta_cost[j:j+n_f], color=cycle[k%len(cycle)])\n",
    "            j += n_f\n",
    "            k += 1\n",
    "    ax[i].set_title(f'Direction {i+1}')\n",
    "    ax[i].set_xlabel('Feature Index')\n",
    "    ax[i].set_ylabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:27.842335Z",
     "iopub.status.busy": "2025-11-26T03:16:27.842335Z",
     "iopub.status.idle": "2025-11-26T03:16:30.612026Z",
     "shell.execute_reply": "2025-11-26T03:16:30.612026Z"
    }
   },
   "outputs": [],
   "source": [
    "n_div = globe_ce.deltas_div.shape[0]\n",
    "min_costs = np.zeros((n_div, globe_ce.x_aff.shape[0]))\n",
    "min_costs_idxs = np.zeros((n_div, globe_ce.x_aff.shape[0]))\n",
    "for i in range(n_div):  \n",
    "    cor_s, cos_s, k_s = globe_ce.scale(globe_ce.deltas_div[i], disable_tqdm=False, vector=True)  \n",
    "    min_costs[i], min_costs_idxs[i] = globe_ce.min_scalar_costs(cos_s, return_idxs=True, inf=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:30.615532Z",
     "iopub.status.busy": "2025-11-26T03:16:30.615029Z",
     "iopub.status.idle": "2025-11-26T03:16:31.346594Z",
     "shell.execute_reply": "2025-11-26T03:16:31.346594Z"
    }
   },
   "outputs": [],
   "source": [
    "ces = globe_ce.round_categorical(globe_ce.x_aff+globe_ce.best_delta) if globe_ce.n_categorical else globe_ce.x_aff+globe_ce.best_delta\n",
    "counterfactual_X_global_ce = pd.DataFrame(ces, columns=X_test.columns)\n",
    "counterfactual_X_global_ce = postprocessing(counterfactual_X_global_ce)\n",
    "counterfactual_y_global_ce = model_raw.predict(counterfactual_X_global_ce.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:31.349598Z",
     "iopub.status.busy": "2025-11-26T03:16:31.348597Z",
     "iopub.status.idle": "2025-11-26T03:16:32.130617Z",
     "shell.execute_reply": "2025-11-26T03:16:32.130114Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Coverage (Globe CE):', counterfactual_y_global_ce.sum()/len(counterfactual_y_global_ce))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:32.132628Z",
     "iopub.status.busy": "2025-11-26T03:16:32.132628Z",
     "iopub.status.idle": "2025-11-26T03:16:32.927976Z",
     "shell.execute_reply": "2025-11-26T03:16:32.927472Z"
    }
   },
   "outputs": [],
   "source": [
    "factual_X = pd.DataFrame(globe_ce.x_aff, columns=df_explain.columns)\n",
    "factual_y = model_raw.predict(factual_X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:32.930980Z",
     "iopub.status.busy": "2025-11-26T03:16:32.929980Z",
     "iopub.status.idle": "2025-11-26T03:16:33.776881Z",
     "shell.execute_reply": "2025-11-26T03:16:33.776881Z"
    }
   },
   "outputs": [],
   "source": [
    "y_target = torch.ones(factual_X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:33.779930Z",
     "iopub.status.busy": "2025-11-26T03:16:33.779930Z",
     "iopub.status.idle": "2025-11-26T03:16:34.590270Z",
     "shell.execute_reply": "2025-11-26T03:16:34.589766Z"
    }
   },
   "outputs": [],
   "source": [
    "costs_vector = globe_ce.feature_costs_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AReS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:34.593429Z",
     "iopub.status.busy": "2025-11-26T03:16:34.593429Z",
     "iopub.status.idle": "2025-11-26T03:16:35.437095Z",
     "shell.execute_reply": "2025-11-26T03:16:35.436593Z"
    }
   },
   "outputs": [],
   "source": [
    "# AReS initiated to determine bin widths for costs\n",
    "from explainers.ares import AReS\n",
    "ares = AReS(model=model_raw, dataset=dataset, X=factual_X, n_bins=10, normalise=normalise)  # Use raw model for AReS  # 1MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:35.440099Z",
     "iopub.status.busy": "2025-11-26T03:16:35.439098Z",
     "iopub.status.idle": "2025-11-26T03:16:37.195057Z",
     "shell.execute_reply": "2025-11-26T03:16:37.195057Z"
    }
   },
   "outputs": [],
   "source": [
    "ares.generate_itemsets(apriori_threshold=0.2, max_width=None, # defaults to e2-1\n",
    "                       affected_subgroup=None, save_copy=False)\n",
    "ares.generate_groundset(max_width=None, RL_reduction=True,\n",
    "                        then_generation=None, save_copy=False)\n",
    "lams = [1, 0]  # can play around with these lambda values\n",
    "ares.evaluate_groundset(lams=lams, r=194, save_mode=1,\n",
    "                        disable_tqdm=False, plot_accuracy=True)\n",
    "ares.select_groundset(s=194)\n",
    "ares.optimise_groundset(lams=lams, factor=1, print_updates=False,\n",
    "                        print_terms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:37.198060Z",
     "iopub.status.busy": "2025-11-26T03:16:37.198060Z",
     "iopub.status.idle": "2025-11-26T03:16:37.937588Z",
     "shell.execute_reply": "2025-11-26T03:16:37.937588Z"
    }
   },
   "outputs": [],
   "source": [
    "counterfactual_X_ares = pd.DataFrame(ares.R.cfx_matrix[0], columns=X_test.columns)\n",
    "counterfactual_X_ares = postprocessing(counterfactual_X_ares)\n",
    "counterfactual_y_ares = model_raw.predict(counterfactual_X_ares.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:37.940593Z",
     "iopub.status.busy": "2025-11-26T03:16:37.939592Z",
     "iopub.status.idle": "2025-11-26T03:16:38.723157Z",
     "shell.execute_reply": "2025-11-26T03:16:38.723157Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Coverage (AReS):', counterfactual_y_ares.sum()/len(counterfactual_y_ares))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diverse Counterfactual Explanation (DiCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:38.725265Z",
     "iopub.status.busy": "2025-11-26T03:16:38.725265Z",
     "iopub.status.idle": "2025-11-26T03:16:39.527897Z",
     "shell.execute_reply": "2025-11-26T03:16:39.527897Z"
    }
   },
   "outputs": [],
   "source": [
    "backend = 'PYT'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:39.530902Z",
     "iopub.status.busy": "2025-11-26T03:16:39.530902Z",
     "iopub.status.idle": "2025-11-26T03:16:40.534455Z",
     "shell.execute_reply": "2025-11-26T03:16:40.533952Z"
    }
   },
   "outputs": [],
   "source": [
    "import dice_ml\n",
    "\n",
    "m = dice_ml.Model(model=model_raw, backend='PYT')  \n",
    "\n",
    "factual_X_ext = factual_X.copy()\n",
    "factual_X_ext[target_name] = factual_y\n",
    "\n",
    "dice_features = factual_X.columns.drop(['Race = Asian', 'Race = Other']).to_list()\n",
    "\n",
    "d = dice_ml.Data(dataframe=factual_X_ext, continuous_features=dice_features, outcome_name = target_name)\n",
    "\n",
    "dice_explainer = dice_ml.Dice(d, m, method=\"random\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:16:41.368155Z",
     "iopub.status.busy": "2025-11-26T03:16:41.368155Z",
     "iopub.status.idle": "2025-11-26T03:17:17.117073Z",
     "shell.execute_reply": "2025-11-26T03:17:17.117073Z"
    }
   },
   "outputs": [],
   "source": [
    "dice_results = dice_explainer.generate_counterfactuals(query_instances=factual_X, features_to_vary=dice_features, desired_class=\"opposite\", total_CFs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:17:17.120076Z",
     "iopub.status.busy": "2025-11-26T03:17:17.120076Z",
     "iopub.status.idle": "2025-11-26T03:17:17.680236Z",
     "shell.execute_reply": "2025-11-26T03:17:17.680236Z"
    }
   },
   "outputs": [],
   "source": [
    "dice_df_list = []\n",
    "for cf in dice_results.cf_examples_list:\n",
    "    cf_df = cf.final_cfs_df\n",
    "    dice_df_list.append(cf_df)\n",
    "\n",
    "counterfactual_X_dice = pd.concat(dice_df_list).reset_index(drop=True).drop(target_name, axis=1)\n",
    "counterfactual_X_dice = postprocessing(counterfactual_X_dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:17:17.683240Z",
     "iopub.status.busy": "2025-11-26T03:17:17.683240Z",
     "iopub.status.idle": "2025-11-26T03:17:18.244313Z",
     "shell.execute_reply": "2025-11-26T03:17:18.243806Z"
    }
   },
   "outputs": [],
   "source": [
    "counterfactual_y_dice = model_raw.predict(counterfactual_X_dice.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:17:18.247317Z",
     "iopub.status.busy": "2025-11-26T03:17:18.246318Z",
     "iopub.status.idle": "2025-11-26T03:17:18.652881Z",
     "shell.execute_reply": "2025-11-26T03:17:18.652376Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Coverage (DiCE):', counterfactual_y_dice.sum()/len(counterfactual_y_dice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DICE: Computing OT Distance between CF predictions and target\")\n",
    "print(\"=\"*80)\n",
    "y_target_tensor = y_target\n",
    "\n",
    "dice_y_prob = model.predict_proba(counterfactual_X_dice.values)\n",
    "dice_y_prob_tensor = torch.FloatTensor(dice_y_prob)\n",
    "\n",
    "\n",
    "from explainers.distances import WassersteinDivergence\n",
    "wd = WassersteinDivergence()\n",
    "ot_dist_dice_y, _ = wd.distance(\n",
    "    y_s=dice_y_prob_tensor,\n",
    "    y_t=y_target_tensor,\n",
    "    delta=0.1\n",
    ")\n",
    "\n",
    "print(f\"DICE Y Probability OT Distance to Target: {ot_dist_dice_y:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributional Counterfactual Explanation (DCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:17:19.067256Z",
     "iopub.status.busy": "2025-11-26T03:17:19.066256Z",
     "iopub.status.idle": "2025-11-26T03:17:19.351365Z",
     "shell.execute_reply": "2025-11-26T03:17:19.350860Z"
    }
   },
   "outputs": [],
   "source": [
    "from explainers.dce import DistributionalCounterfactualExplainer\n",
    "\n",
    "delta = 1e-5\n",
    "alpha = 0.05\n",
    "N = 10\n",
    "\n",
    "explain_columns = df_explain.columns\n",
    "\n",
    "explainer = DistributionalCounterfactualExplainer(\n",
    "    model=model_raw, \n",
    "    df_X=factual_X, \n",
    "    explain_columns=explain_columns,\n",
    "    y_target=y_target, \n",
    "    lr=0.1, \n",
    "    n_proj=N,\n",
    "    delta=delta,\n",
    "    costs_vector=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:17:19.757354Z",
     "iopub.status.busy": "2025-11-26T03:17:19.757354Z",
     "iopub.status.idle": "2025-11-26T03:17:20.183401Z",
     "shell.execute_reply": "2025-11-26T03:17:20.182899Z"
    }
   },
   "outputs": [],
   "source": [
    "explainer.optimize(U_1=0.01, U_2=0.2, l=0.7, r=0.85, max_iter=100, tau=1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:17:21.097839Z",
     "iopub.status.busy": "2025-11-26T03:17:21.096840Z",
     "iopub.status.idle": "2025-11-26T03:17:21.515290Z",
     "shell.execute_reply": "2025-11-26T03:17:21.515290Z"
    }
   },
   "outputs": [],
   "source": [
    "counterfactual_X_dce = pd.DataFrame(explainer.best_X.detach().numpy(), columns=df_explain.columns)\n",
    "counterfactual_X_dce = postprocessing(counterfactual_X_dce)\n",
    "\n",
    "dtype_dict = dataset.data.drop(columns=[target_name]).dtypes.apply(lambda x: x.name).to_dict()\n",
    "\n",
    "for k, v in dtype_dict.items():\n",
    "    if k in counterfactual_X_dce.columns:\n",
    "        if v[:3] == 'int':\n",
    "            counterfactual_X_dce[k] = counterfactual_X_dce[k].round().astype(v)\n",
    "        else:\n",
    "            counterfactual_X_dce[k] = counterfactual_X_dce[k].astype(v)\n",
    "\n",
    "counterfactual_y_prob_dce = pd.DataFrame(explainer.y.detach().numpy(),columns=[target_name], index=counterfactual_X_dce.index)\n",
    "counterfactual_y_dce = np.int64((counterfactual_y_prob_dce.values > 0.5).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:17:21.518293Z",
     "iopub.status.busy": "2025-11-26T03:17:21.518293Z",
     "iopub.status.idle": "2025-11-26T03:17:21.859263Z",
     "shell.execute_reply": "2025-11-26T03:17:21.858757Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Coverage (DCE):', counterfactual_y_dce.sum()/len(counterfactual_y_dce))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DISCOVER (Distributional Counterfactual Optimization with Variance Reduction)\n",
    "\n",
    "DISCOVER is our improved version of DCE that uses advanced sampling strategies for better optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:17:21.862271Z",
     "iopub.status.busy": "2025-11-26T03:17:21.862271Z",
     "iopub.status.idle": "2025-11-26T03:17:22.871519Z",
     "shell.execute_reply": "2025-11-26T03:17:22.871519Z"
    }
   },
   "outputs": [],
   "source": [
    "from explainers.DCESolver import DCESolver\n",
    "from explainers.cone_sampling.monte_carlo import MonteCarloStrategy\n",
    "# from explainers.data import DataLoader\n",
    "from data_loader.compas import CompasData\n",
    "from explainers.model import Model\n",
    "discover_seed = seed\n",
    "print(f\"DISCOVER seed: {discover_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:17:22.874750Z",
     "iopub.status.busy": "2025-11-26T03:17:22.873740Z",
     "iopub.status.idle": "2025-11-26T03:17:23.287503Z",
     "shell.execute_reply": "2025-11-26T03:17:23.287503Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a minimal DataLoader wrapper for DISCOVER\n",
    "class BaselineDataWrapper:\n",
    "    def __init__(self, df_factual, df_explain, y_test, continuous_cols, categorical_cols):\n",
    "        self.df = df_factual.copy()\n",
    "        self.X_train = df_explain.values\n",
    "        self.y_train = y_test\n",
    "\n",
    "        self.explain_columns = df_explain.columns.tolist()\n",
    "        self.continuous_columns = continuous_cols\n",
    "        self.categorical_columns = categorical_cols\n",
    "\n",
    "        self.mean = df_factual[continuous_cols].mean().to_dict()\n",
    "        self.std = df_factual[continuous_cols].std().to_dict()\n",
    "\n",
    "        for col in continuous_cols:\n",
    "            if self.std[col] == 0:\n",
    "                self.std[col] = 1.0\n",
    "        \n",
    "    def get_X_init(self):\n",
    "        import torch\n",
    "        return torch.from_numpy(self.X_train).float()\n",
    "    \n",
    "    def get_y_target(self):\n",
    "        import torch\n",
    "        return torch.ones(len(self.X_train))\n",
    "\n",
    "\n",
    "continuous_features_discover = ['Priors_Count', 'Time_Served']\n",
    "categorical_features_discover = [col for col in df_explain.columns if col not in continuous_features_discover]\n",
    "\n",
    "discover_data = BaselineDataWrapper(\n",
    "    df_factual=factual_X,\n",
    "    df_explain=factual_X,  \n",
    "    y_test=factual_y,  \n",
    "    continuous_cols=continuous_features_discover,\n",
    "    categorical_cols=categorical_features_discover\n",
    ")\n",
    "\n",
    "print(f\"DISCOVER data wrapper created: {len(factual_X)} samples\")\n",
    "print(f\"Continuous features: {len(continuous_features_discover)}\")\n",
    "print(f\"Categorical features: {len(categorical_features_discover)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:17:23.290506Z",
     "iopub.status.busy": "2025-11-26T03:17:23.290506Z",
     "iopub.status.idle": "2025-11-26T03:17:23.778093Z",
     "shell.execute_reply": "2025-11-26T03:17:23.778093Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize DISCOVER solver\n",
    "discover_solver = DCESolver(model=model, data=discover_data)\n",
    "\n",
    "# Initialize MonteCarlo sampling strategy\n",
    "discover_strategy = MonteCarloStrategy(\n",
    "    explainer=discover_solver,\n",
    "    random_state=discover_seed,\n",
    "    cone_angle=3.14159/4,  # Ï€/4\n",
    "    use_cone_sampling_categorical=True,\n",
    "    use_cone_sampling_continuous=True,\n",
    "    categorical_step=1.2,\n",
    "    continuous_step=0.1,\n",
    "    temperature=2.0,\n",
    "    h = 2\n",
    ")\n",
    "\n",
    "print(\"DISCOVER solver and strategy initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:17:23.781099Z",
     "iopub.status.busy": "2025-11-26T03:17:23.781099Z",
     "iopub.status.idle": "2025-11-26T03:26:49.778371Z",
     "shell.execute_reply": "2025-11-26T03:26:49.778371Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run DISCOVER optimization\n",
    "counterfactual_X_discover_df = discover_solver.explain(\n",
    "    df_factual=factual_X,\n",
    "    explain_columns=factual_X.columns.tolist(),\n",
    "    categorical_columns=categorical_features_discover,\n",
    "    continuous_columns=continuous_features_discover,\n",
    "    y_target=torch.ones(len(factual_X)),\n",
    "    strategy=discover_strategy,\n",
    "    X_init=False,  \n",
    "    n_proj=10,\n",
    "    delta=1e-5,\n",
    "    costs_vector=None,\n",
    "    U_1=0.8,  \n",
    "    U_2=0.6,  \n",
    "    alpha=0.05,\n",
    "    l=0.2,    \n",
    "    r=1,    \n",
    "    kappa=0.05,\n",
    "    max_iter=45,\n",
    "    num_trials=50,\n",
    "    bootstrap=True,\n",
    "    callback=False,\n",
    "    top_k=1,\n",
    "    save_results=False,  \n",
    "    use_global_ranges=False,\n",
    "    target_ot_y=ot_dist_dice_y\n",
    ")\n",
    "\n",
    "print(f\"\\nDISCOVER optimization completed\")\n",
    "print(f\"Best Q found: {discover_solver.best_Q:.6f}\")\n",
    "print(f\"Best iteration: {discover_solver.best_iter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:26:49.781379Z",
     "iopub.status.busy": "2025-11-26T03:26:49.780379Z",
     "iopub.status.idle": "2025-11-26T03:26:50.255645Z",
     "shell.execute_reply": "2025-11-26T03:26:50.255141Z"
    }
   },
   "outputs": [],
   "source": [
    "counterfactual_X_discover = postprocessing(counterfactual_X_discover_df)\n",
    "counterfactual_y_discover = model_raw.predict(counterfactual_X_discover.values)\n",
    "print(f\"DISCOVER counterfactuals: {len(counterfactual_X_discover)} samples\")\n",
    "print(f\"Coverage (DISCOVER): {counterfactual_y_discover.sum()/len(counterfactual_y_discover):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:26:50.257651Z",
     "iopub.status.busy": "2025-11-26T03:26:50.257651Z",
     "iopub.status.idle": "2025-11-26T03:26:50.726009Z",
     "shell.execute_reply": "2025-11-26T03:26:50.726009Z"
    }
   },
   "outputs": [],
   "source": [
    "from explainers.distances import SlicedWassersteinDivergence, WassersteinDivergence\n",
    "from scipy.stats import gaussian_kde, entropy\n",
    "from numpy.linalg import LinAlgError\n",
    "\n",
    "def compute_distance(X_s, X_t):\n",
    "    if isinstance(X_s, pd.DataFrame):\n",
    "        X_s = X_s.apply(pd.to_numeric, errors=\"coerce\").fillna(0).astype(np.float32)\n",
    "        X_s = torch.FloatTensor(X_s.values)\n",
    "    if isinstance(X_t, pd.DataFrame):\n",
    "        X_t = X_t.apply(pd.to_numeric, errors=\"coerce\").fillna(0).astype(np.float32)\n",
    "        X_t = torch.FloatTensor(X_t.values)\n",
    "\n",
    "    if isinstance(X_s, np.ndarray):\n",
    "        X_s = torch.FloatTensor(X_s.astype(np.float32))\n",
    "    if isinstance(X_t, np.ndarray):\n",
    "        X_t = torch.FloatTensor(X_t.astype(np.float32))\n",
    "\n",
    "    if X_s.ndim == 1:\n",
    "        wd = WassersteinDivergence()\n",
    "        distance, _ = wd.distance(X_s, X_t, delta=0.1)\n",
    "    else:\n",
    "        swd = SlicedWassersteinDivergence(\n",
    "                dim=X_s.shape[1], n_proj=5000\n",
    "        )\n",
    "        distance, _ = swd.distance(X_s, X_t, delta=0.1)\n",
    "    return distance.item()\n",
    "\n",
    "\n",
    "def compute_kl_divergence(X_s, X_t):\n",
    "    kl_divergences = []\n",
    "    for i in range(X_s.shape[1]):  # Iterate over columns (features)\n",
    "        try:\n",
    "            # Estimate probability distributions using KDE\n",
    "            kde_s = gaussian_kde(X_s[:, i])\n",
    "            kde_t = gaussian_kde(X_t[:, i])\n",
    "\n",
    "            # Evaluate the densities on a linear space of the same range\n",
    "            x_min = min(X_s[:, i].min(), X_t[:, i].min())\n",
    "            x_max = max(X_s[:, i].max(), X_t[:, i].max())\n",
    "            x = np.linspace(x_min, x_max, 1000)\n",
    "\n",
    "            # Compute the KL divergence (entropy)\n",
    "            kl_div = entropy(kde_s(x), kde_t(x))\n",
    "        except LinAlgError:\n",
    "            # Catch the singular matrix error and set the divergence to infinity\n",
    "            kl_div = np.inf\n",
    "\n",
    "        kl_divergences.append(kl_div)\n",
    "\n",
    "    # Aggregate the KL divergences\n",
    "    total_kl_divergence = np.sum(kl_divergences)  # Or use np.mean for average\n",
    "    return total_kl_divergence\n",
    "\n",
    "def gaussian_kernel(x, y, sigma=1.0):\n",
    "    \"\"\"Compute the Gaussian kernel between x and y\"\"\"\n",
    "    return np.exp(-np.linalg.norm(x - y) ** 2 / (2 * sigma ** 2))\n",
    "\n",
    "def mmd(X_s, X_t, kernel=gaussian_kernel):\n",
    "    \"\"\"Compute the Maximum Mean Discrepancy (MMD) between two samples X_s and X_t\"\"\"\n",
    "    n = X_s.shape[0]\n",
    "    m = X_t.shape[0]\n",
    "\n",
    "    # Calculate the kernel values between all points in the first sample\n",
    "    XX = np.sum([kernel(X_s[i], X_s[j]) for i in range(n) for j in range(n)])\n",
    "    \n",
    "    # Calculate the kernel values between all points in the second sample\n",
    "    YY = np.sum([kernel(X_t[i], X_t[j]) for i in range(m) for j in range(m)])\n",
    "    \n",
    "    # Calculate the kernel values between all points across the two samples\n",
    "    XY = np.sum([kernel(X_s[i], X_t[j]) for i in range(n) for j in range(m)])\n",
    "\n",
    "    return XX / (n ** 2) + YY / (m ** 2) - 2 * XY / (n * m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:26:50.729012Z",
     "iopub.status.busy": "2025-11-26T03:26:50.729012Z",
     "iopub.status.idle": "2025-11-26T03:26:51.127550Z",
     "shell.execute_reply": "2025-11-26T03:26:51.127047Z"
    }
   },
   "outputs": [],
   "source": [
    "cov_ares = counterfactual_y_ares.sum()/len(counterfactual_y_ares)  \n",
    "cov_global_ce = counterfactual_y_global_ce.sum()/len(counterfactual_y_global_ce)\n",
    "cov_dice = counterfactual_y_dice.sum()/len(counterfactual_y_dice)\n",
    "cov_dce = counterfactual_y_dce.sum()/len(counterfactual_y_dce) \n",
    "cov_discover = counterfactual_y_discover.sum()/len(counterfactual_y_discover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:26:51.130554Z",
     "iopub.status.busy": "2025-11-26T03:26:51.129554Z",
     "iopub.status.idle": "2025-11-26T03:26:51.572716Z",
     "shell.execute_reply": "2025-11-26T03:26:51.572716Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Coverage (AReS):', cov_ares)  \n",
    "print('Coverage (Globe CE):', cov_global_ce)\n",
    "print('Coverage (DiCE):', cov_dice)\n",
    "print('Coverage (DCE):', cov_dce)  \n",
    "print('Coverage (DISCOVER):', cov_discover) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:26:51.575895Z",
     "iopub.status.busy": "2025-11-26T03:26:51.575895Z",
     "iopub.status.idle": "2025-11-26T03:27:05.333044Z",
     "shell.execute_reply": "2025-11-26T03:27:05.333044Z"
    }
   },
   "outputs": [],
   "source": [
    "ot_dist_ares = compute_distance(X_s=counterfactual_X_ares, X_t=factual_X)  \n",
    "ot_dist_global_ce = compute_distance(X_s=counterfactual_X_global_ce, X_t=factual_X)\n",
    "ot_dist_dce = compute_distance(X_s=counterfactual_X_dce, X_t=factual_X) \n",
    "ot_dist_dice = compute_distance(X_s=counterfactual_X_dice.dropna(), X_t=factual_X)\n",
    "ot_dist_discover = compute_distance(X_s=counterfactual_X_discover, X_t=factual_X) \n",
    "\n",
    "print('X Distance (AReS):', ot_dist_ares)  \n",
    "print('X Distance (Globe CE):', ot_dist_global_ce)\n",
    "print('X Distance (DiCE):', ot_dist_dice)\n",
    "print('X Distance (DCE):', ot_dist_dce)  \n",
    "print('X Distance (DISCOVER):', ot_dist_discover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Y Distance Evaluation (Predicted Y Probability vs Target Y) ==========\n",
    "print(\"=\"*80)\n",
    "print(\"Y Distance Evaluation: Predicted Y Probability vs Target Y\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "y_target_tensor = y_target\n",
    "\n",
    "# Get predicted y PROBABILITIES (not binary 0/1) for each method's counterfactual results\n",
    "y_prob_globe = model_raw.predict_proba(counterfactual_X_global_ce.values)[:, 1]\n",
    "y_prob_ares = model_raw.predict_proba(counterfactual_X_ares.values)[:, 1]\n",
    "y_prob_dice = model_raw.predict_proba(counterfactual_X_dice.values)[:, 1]\n",
    "counterfactual_X_dce = counterfactual_X_dce.apply(pd.to_numeric, errors=\"coerce\").fillna(0).astype(np.float32)\n",
    "y_prob_dce = model_raw.predict_proba(counterfactual_X_dce.values)[:, 1]\n",
    "y_prob_discover = model_raw.predict_proba(counterfactual_X_discover.values)[:, 1]\n",
    "\n",
    "# Convert to tensors\n",
    "y_prob_globe_tensor = torch.FloatTensor(y_prob_globe)\n",
    "y_prob_ares_tensor = torch.FloatTensor(y_prob_ares)\n",
    "y_prob_dice_tensor = torch.FloatTensor(y_prob_dice)\n",
    "y_prob_dce_tensor = torch.FloatTensor(y_prob_dce)\n",
    "y_prob_discover_tensor = torch.FloatTensor(y_prob_discover)\n",
    "\n",
    "# Compute OT distance between predicted probabilities and target y (all 1s)\n",
    "ot_dist_y_globe = compute_distance(X_s=y_prob_globe_tensor, X_t=y_target_tensor)\n",
    "ot_dist_y_ares = compute_distance(X_s=y_prob_ares_tensor, X_t=y_target_tensor)\n",
    "ot_dist_y_dice = compute_distance(X_s=y_prob_dice_tensor, X_t=y_target_tensor)\n",
    "ot_dist_y_dce = compute_distance(X_s=y_prob_dce_tensor, X_t=y_target_tensor)\n",
    "ot_dist_y_discover = compute_distance(X_s=y_prob_discover_tensor, X_t=y_target_tensor)\n",
    "\n",
    "print(f'Y Probability Distance (AReS vs Target): {ot_dist_y_ares:.6f}')\n",
    "print(f'Y Probability Distance (GLOBE vs Target): {ot_dist_y_globe:.6f}')\n",
    "print(f'Y Probability Distance (DiCE vs Target): {ot_dist_y_dice:.6f}')\n",
    "print(f'Y Probability Distance (DCE vs Target): {ot_dist_y_dce:.6f}')\n",
    "print(f'Y Probability Distance (DISCOVER vs Target): {ot_dist_y_discover:.6f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Y (Risk) CDF Curve Visualization with Diagnostics ==========\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "y_factual = model_raw.predict_proba(factual_X.values)[:, 1]\n",
    "y_ares_cf = model_raw.predict_proba(counterfactual_X_ares.values)[:, 1]\n",
    "y_globe_cf = model_raw.predict_proba(counterfactual_X_global_ce.values)[:, 1]\n",
    "y_dice_cf = model_raw.predict_proba(counterfactual_X_dice.values)[:, 1]\n",
    "y_discover_cf = model_raw.predict_proba(counterfactual_X_discover.values)[:, 1]\n",
    "y_target_vals = y_target\n",
    "y_dce_cf = model_raw.predict_proba(counterfactual_X_dce.values)[:, 1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7), dpi=120)\n",
    "ax.plot(np.sort(y_dce_cf), np.linspace(0, 1, len(y_dce_cf)),\n",
    "        label=\"DCE\", color=\"#F39C12\",\n",
    "        linewidth=2, alpha=0.85)\n",
    "\n",
    "ax.plot(np.sort(y_factual), np.linspace(0, 1, len(y_factual)),\n",
    "        label=\"Factual\", color=\"gray\",\n",
    "        linewidth=2.5, alpha=0.7, linestyle=\":\")\n",
    "\n",
    "ax.plot(np.sort(y_ares_cf), np.linspace(0, 1, len(y_ares_cf)),\n",
    "        label=\"AReS\", color=\"#FF6B6B\",\n",
    "        linewidth=2, alpha=0.85)\n",
    "\n",
    "ax.plot(np.sort(y_globe_cf), np.linspace(0, 1, len(y_globe_cf)),\n",
    "        label=\"GLOBE\", color=\"#7B2CBF\",\n",
    "        linewidth=2, alpha=0.85)\n",
    "\n",
    "ax.plot(np.sort(y_dice_cf), np.linspace(0, 1, len(y_dice_cf)),\n",
    "        label=f\"DiCE\", color=\"#4ECDC4\",\n",
    "        linewidth=2, alpha=0.85)\n",
    "\n",
    "ax.plot(np.sort(y_discover_cf), np.linspace(0, 1, len(y_discover_cf)),\n",
    "        label=\"DISCOVER\", color=\"#1E88E5\",\n",
    "        linewidth=2.5, alpha=0.9)\n",
    "\n",
    "ax.plot(np.sort(y_target_vals), np.linspace(0, 1, len(y_target_vals)),\n",
    "        label=\"Target\", color=\"black\",\n",
    "        linestyle=\"--\", linewidth=3, alpha=0.95)\n",
    "\n",
    "ax.axvline(0.5, color=\"red\", linestyle=\":\", linewidth=1.5, alpha=0.4)\n",
    "\n",
    "ax.set_xlabel(\"Risk Probability (Y)\", fontsize=18, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Cumulative Probability (Quantile)\", fontsize=18, fontweight=\"bold\")\n",
    "ax.set_title(\"Empirical CDF Comparison (Y)\",\n",
    "            fontsize=25, fontweight=\"bold\", pad=15)\n",
    "\n",
    "ax.legend(loc=\"upper left\", fontsize=14, frameon=True, shadow=True)\n",
    "ax.grid(True, alpha=0.3, linestyle=\"--\", linewidth=0.5)\n",
    "ax.set_xlim([0, 1.05])\n",
    "ax.set_ylim([0, 1.05])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"cdf.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_five_methods_comparison(dice_dist, globe_dist, discover_dist, ares_dist, dce_dist, top_n=10, save_path=None):\n",
    "\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 30,         \n",
    "        'axes.titlesize': 30,\n",
    "        'axes.labelsize': 30,\n",
    "        'xtick.labelsize': 15,\n",
    "        'ytick.labelsize': 15,\n",
    "        'legend.fontsize': 30\n",
    "    })\n",
    "\n",
    "\n",
    "    dice_sorted = np.sort(dice_dist)[::-1]\n",
    "    globe_sorted = np.sort(globe_dist)[::-1]\n",
    "    discover_sorted = np.sort(discover_dist)[::-1]\n",
    "    ares_sorted = np.sort(ares_dist)[::-1]\n",
    "    dce_sorted = np.sort(dce_dist)[::-1]\n",
    "\n",
    "    n_samples = len(dice_sorted)\n",
    "    x_positions = np.arange(n_samples)\n",
    "\n",
    "    global_max = max(dice_sorted.max(), globe_sorted.max(), discover_sorted.max(),\n",
    "                     ares_sorted.max(), dce_sorted.max())\n",
    "    y_limit = global_max * 1.15\n",
    "\n",
    "    # fig, axes = plt.subplots(5, 1, figsize=(16, 18), sharex=True, dpi=120)\n",
    "    fig, axes = plt.subplots(5, 1, figsize=(16, 15), sharex=True, dpi=120)\n",
    "\n",
    "    methods = [\n",
    "        ('ARES', ares_sorted, '#2ECC71'),\n",
    "        ('GLobe', globe_sorted, '#3498DB'),\n",
    "        ('DiCE', dice_sorted, '#E74C3C'),\n",
    "        ('DCE', dce_sorted, '#F39C12'),    \n",
    "        ('DISCOVER', discover_sorted, '#9B59B6'),\n",
    "\n",
    "    ]\n",
    "\n",
    "    for idx, (name, sorted_dist, color) in enumerate(methods):\n",
    "        ax = axes[idx]\n",
    "\n",
    "        bars = ax.bar(x_positions, sorted_dist,\n",
    "                      width=1.0,\n",
    "                      alpha=0.7,\n",
    "                      color=color,\n",
    "                      edgecolor='none')\n",
    "\n",
    "        for i in range(min(top_n, n_samples)):\n",
    "            bars[i].set_color(color)\n",
    "            bars[i].set_alpha(0.95)\n",
    "            bars[i].set_edgecolor('black')\n",
    "            bars[i].set_linewidth(0.5)\n",
    "\n",
    "        ax.set_ylim([0, y_limit])\n",
    "        ax.set_ylabel('OT Distance', fontsize=25, fontweight='bold')\n",
    "        ax.set_title(f'{name}', fontsize=25, fontweight='bold', loc='left', pad=10)\n",
    "        ax.grid(True, alpha=0.3, axis='y', linestyle='--', linewidth=0.7)\n",
    "\n",
    "        textstr = (f'Mean: {sorted_dist.mean():.4f}\\n'\n",
    "                   f'Std:  {sorted_dist.std():.4f}\\n'\n",
    "                   f'Max:  {sorted_dist.max():.4f}')\n",
    "        props = dict(boxstyle='round', facecolor='wheat', alpha=0.85)\n",
    "        # ax.text(0.98, 0.97, textstr, transform=ax.transAxes, fontsize=10,\n",
    "        #         verticalalignment='top', horizontalalignment='right',\n",
    "        #         bbox=props, family='monospace')\n",
    "\n",
    "    axes[4].set_xlabel('Sample Index',\n",
    "                       fontsize=25, fontweight='bold')\n",
    "    axes[4].set_xlim([-1, n_samples])\n",
    "\n",
    "    fig.suptitle(f'Samplewise OT ({n_samples} samples)',\n",
    "                 fontsize=40, fontweight='bold', y=0.995)\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    plt.tight_layout(pad=0.4)\n",
    "    fig.subplots_adjust(hspace=0.3)\n",
    "\n",
    "    if save_path is not None:\n",
    "        fig.savefig(save_path, format='pdf', bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "factual_X_aligned = factual_X.reset_index(drop=True).copy()\n",
    "counterfactual_X_dice_aligned = counterfactual_X_dice.reset_index(drop=True).copy()\n",
    "counterfactual_X_globe_aligned = counterfactual_X_global_ce.reset_index(drop=True).copy()\n",
    "counterfactual_X_discover_aligned = counterfactual_X_discover.reset_index(drop=True).copy()\n",
    "\n",
    "counterfactual_X_ares_aligned = counterfactual_X_ares.reset_index(drop=True).copy()\n",
    "counterfactual_X_dce_aligned = counterfactual_X_dce.reset_index(drop=True).copy()\n",
    "\n",
    "print('ARES individual OT distances...')\n",
    "ares_individual_distances = compute_ot_individual_distances(\n",
    "    factual_X_aligned, counterfactual_X_ares_aligned\n",
    ")\n",
    "\n",
    "\n",
    "print('GLobe individual OT distances...')\n",
    "globe_individual_distances = compute_ot_individual_distances(\n",
    "    factual_X_aligned, counterfactual_X_globe_aligned\n",
    ")\n",
    "\n",
    "print('DiCE individual OT distances...')\n",
    "dice_individual_distances = compute_ot_individual_distances(\n",
    "    factual_X_aligned, counterfactual_X_dice_aligned\n",
    ")\n",
    "\n",
    "print('DCE individual OT distances...')\n",
    "dce_individual_distances = compute_ot_individual_distances(\n",
    "    factual_X_aligned, counterfactual_X_dce_aligned\n",
    ")\n",
    "\n",
    "print('DISCOVER individual OT distances...')\n",
    "discover_individual_distances = compute_ot_individual_distances(\n",
    "    factual_X_aligned, counterfactual_X_discover_aligned\n",
    ")\n",
    "\n",
    "plot_five_methods_comparison(\n",
    "    dice_individual_distances,\n",
    "    globe_individual_distances,\n",
    "    discover_individual_distances,\n",
    "    ares_individual_distances,\n",
    "    dce_individual_distances,\n",
    "    top_n=10,\n",
    "    save_path='ot_comparison_compas_mlp.pdf'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:27:05.335555Z",
     "iopub.status.busy": "2025-11-26T03:27:05.335555Z",
     "iopub.status.idle": "2025-11-26T03:27:06.010548Z",
     "shell.execute_reply": "2025-11-26T03:27:06.010548Z"
    }
   },
   "outputs": [],
   "source": [
    "print('X MMD (AReS):', mmd(X_s=counterfactual_X_ares.values, X_t=factual_X.values)) \n",
    "print('X MMD (Globe CE):', mmd(X_s=counterfactual_X_global_ce.values, X_t=factual_X.values))\n",
    "print('X MMD (DiCE):', mmd(X_s=counterfactual_X_dice.dropna().values, X_t=factual_X.values))\n",
    "print('X MMD (DCE):', mmd(X_s=counterfactual_X_dce.values, X_t=factual_X.values))  \n",
    "print('X MMD (DISCOVER):', mmd(X_s=counterfactual_X_discover.values, X_t=factual_X.values)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:27:06.013556Z",
     "iopub.status.busy": "2025-11-26T03:27:06.013556Z",
     "iopub.status.idle": "2025-11-26T03:27:06.613246Z",
     "shell.execute_reply": "2025-11-26T03:27:06.613246Z"
    }
   },
   "outputs": [],
   "source": [
    "print('X KL-Divergence (AReS):', \n",
    "      compute_kl_divergence(X_s=counterfactual_X_ares.values, X_t=factual_X.values))\n",
    "print('X KL-Divergence (Globe CE):', \n",
    "      compute_kl_divergence(X_s=counterfactual_X_global_ce.values, X_t=factual_X.values))\n",
    "print('X KL-Divergence (DiCE):', \n",
    "      compute_kl_divergence(X_s=counterfactual_X_dice.dropna().values, X_t=factual_X.values))\n",
    "print('X KL-Divergence (DCE):', \n",
    "      compute_kl_divergence(X_s=counterfactual_X_dce.values, X_t=factual_X.values))\n",
    "print('X KL-Divergence (DISCOVER):',\n",
    "      compute_kl_divergence(X_s=counterfactual_X_discover.values, X_t=factual_X.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:27:06.616249Z",
     "iopub.status.busy": "2025-11-26T03:27:06.616249Z",
     "iopub.status.idle": "2025-11-26T03:27:07.175043Z",
     "shell.execute_reply": "2025-11-26T03:27:07.175043Z"
    }
   },
   "outputs": [],
   "source": [
    "ares_diff_pct = []  \n",
    "globe_ce_diff_pct = []\n",
    "dice_diff_pct = []\n",
    "dce_diff_pct = [] \n",
    "discover_diff_pct = []\n",
    "for column in df_explain.columns:\n",
    "    ares_pct = (counterfactual_X_ares[column] - factual_X[column]).abs().sum() / (1e-7 + factual_X[column].abs().sum()) \n",
    "    globe_ce_pct = (counterfactual_X_global_ce[column] - factual_X[column]).abs().sum() / (1e-7 + factual_X[column].abs().sum())\n",
    "    dice_pct = (counterfactual_X_dice[column] - factual_X[column]).abs().sum() / (1e-7 + factual_X[column].abs().sum())\n",
    "    dce_pct = (counterfactual_X_dce[column] - factual_X[column]).abs().sum() / (1e-7 + factual_X[column].abs().sum())  \n",
    "    discover_pct = (counterfactual_X_discover[column] - factual_X[column]).abs().sum() / (1e-7 + factual_X[column].abs().sum())\n",
    "\n",
    "    ares_diff_pct.append({column: ares_pct}) \n",
    "    globe_ce_diff_pct.append({column: globe_ce_pct})\n",
    "    dice_diff_pct.append({column: dice_pct})\n",
    "    dce_diff_pct.append({column: dce_pct}) \n",
    "    discover_diff_pct.append({column: discover_pct})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:27:07.178555Z",
     "iopub.status.busy": "2025-11-26T03:27:07.177554Z",
     "iopub.status.idle": "2025-11-26T03:27:07.693868Z",
     "shell.execute_reply": "2025-11-26T03:27:07.693868Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_cost(delta, costs_vector):\n",
    "    return np.linalg.norm(delta @ np.diag(costs_vector)) \n",
    "\n",
    "\n",
    "def compute_absolute_difference(counterfactual_X, factual_X):\n",
    "    columns = counterfactual_X.columns.drop(['Priors_Count', 'Time_Served'])\n",
    "    diff_list = []\n",
    "\n",
    "    for column in columns:\n",
    "        diff_list.append((counterfactual_X[column] - factual_X[column]).abs().mean())\n",
    "\n",
    "    return np.nanmean(diff_list)\n",
    "\n",
    "def compute_statistic_difference(counterfactual_X, factual_X, metric, columns):\n",
    "    diff_list = []\n",
    "    for column in columns:\n",
    "        val_cf = counterfactual_X[column].agg(metric)\n",
    "        val_f = factual_X[column].agg(metric)\n",
    "        diff_list.append(abs(val_cf - val_f)/(abs(val_f)) * 100)\n",
    "\n",
    "    return np.nanmean(diff_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:27:07.696872Z",
     "iopub.status.busy": "2025-11-26T03:27:07.696872Z",
     "iopub.status.idle": "2025-11-26T03:27:08.232897Z",
     "shell.execute_reply": "2025-11-26T03:27:08.232392Z"
    }
   },
   "outputs": [],
   "source": [
    "ares_delta = (counterfactual_X_ares - factual_X).dropna().values \n",
    "globe_ce_delta = (counterfactual_X_global_ce - factual_X).values\n",
    "dce_delta = (counterfactual_X_dce - factual_X).dropna().values  \n",
    "dice_delta = (counterfactual_X_dice - factual_X).dropna().values\n",
    "discover_delta = (counterfactual_X_discover - factual_X).dropna().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:27:08.235905Z",
     "iopub.status.busy": "2025-11-26T03:27:08.234904Z",
     "iopub.status.idle": "2025-11-26T03:27:08.739565Z",
     "shell.execute_reply": "2025-11-26T03:27:08.739565Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Cost (AReS):', compute_cost(ares_delta, costs_vector)) \n",
    "print('Cost (Globe CE):', compute_cost(globe_ce_delta, costs_vector))\n",
    "print('Cost (DiCE):', compute_cost(dice_delta, costs_vector))\n",
    "print('Cost (DCE):', compute_cost(dce_delta, costs_vector))  \n",
    "print('Cost (DISCOVER):', compute_cost(discover_delta, costs_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:27:11.707361Z",
     "iopub.status.busy": "2025-11-26T03:27:11.707361Z",
     "iopub.status.idle": "2025-11-26T03:27:12.281450Z",
     "shell.execute_reply": "2025-11-26T03:27:12.281450Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_average_pairwise_distance(counterfactual_X):\n",
    "    n = len(counterfactual_X)\n",
    "    total_distance = 0\n",
    "    count = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            dist = np.linalg.norm(counterfactual_X.iloc[i] - counterfactual_X.iloc[j])\n",
    "            total_distance += dist\n",
    "            count += 1\n",
    "\n",
    "    if count > 0:\n",
    "        average_distance = total_distance / count\n",
    "    else:\n",
    "        average_distance = 0\n",
    "\n",
    "    return average_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:27:12.284844Z",
     "iopub.status.busy": "2025-11-26T03:27:12.284844Z",
     "iopub.status.idle": "2025-11-26T03:27:12.855349Z",
     "shell.execute_reply": "2025-11-26T03:27:12.855349Z"
    }
   },
   "outputs": [],
   "source": [
    "diversity_factual = compute_average_pairwise_distance(factual_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:27:12.858561Z",
     "iopub.status.busy": "2025-11-26T03:27:12.858561Z",
     "iopub.status.idle": "2025-11-26T03:27:13.303316Z",
     "shell.execute_reply": "2025-11-26T03:27:13.302813Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Diversity (Factual)', diversity_factual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:27:13.305320Z",
     "iopub.status.busy": "2025-11-26T03:27:13.305320Z",
     "iopub.status.idle": "2025-11-26T03:27:13.762696Z",
     "shell.execute_reply": "2025-11-26T03:27:13.762696Z"
    }
   },
   "outputs": [],
   "source": [
    "diversity_ares = compute_average_pairwise_distance(counterfactual_X_ares)  \n",
    "diversity_global_ce = compute_average_pairwise_distance(counterfactual_X_global_ce)\n",
    "diversity_dice = compute_average_pairwise_distance(counterfactual_X_dice.dropna())\n",
    "diversity_dce = compute_average_pairwise_distance(counterfactual_X_dce)  \n",
    "diversity_discover = compute_average_pairwise_distance(counterfactual_X_discover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:27:13.765699Z",
     "iopub.status.busy": "2025-11-26T03:27:13.765699Z",
     "iopub.status.idle": "2025-11-26T03:27:14.192996Z",
     "shell.execute_reply": "2025-11-26T03:27:14.192494Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Diversity (AReS):', diversity_ares)  \n",
    "print('Diversity (Globe CE):', diversity_global_ce)\n",
    "print('Diversity (DiCE):', diversity_dice)\n",
    "print('Diversity (DCE):', diversity_dce)  \n",
    "print('Diversity (DISCOVER):', diversity_discover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T03:27:14.195000Z",
     "iopub.status.busy": "2025-11-26T03:27:14.195000Z",
     "iopub.status.idle": "2025-11-26T03:27:14.551407Z",
     "shell.execute_reply": "2025-11-26T03:27:14.550901Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Effective Diversity (AReS):', diversity_ares/ot_dist_ares * cov_ares)  \n",
    "print('Effective Diversity (Globe CE):', diversity_global_ce/ot_dist_global_ce * cov_global_ce)\n",
    "print('Effective Diversity (DiCE):', diversity_dice/ot_dist_dice * cov_dice)\n",
    "print('Effective Diversity (DCE):', diversity_dce/ot_dist_dce * cov_dce)  \n",
    "print('Effective Diversity (DISCOVER):', diversity_discover/ot_dist_discover * cov_discover)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DCE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
